---
title: "Calibration Curve"
author: "Uriah Finkel"
date: "2024-05-15"
description: "An example of creating a calibration curve using rtichoke and scikit-learn."
categories: [calibration, scikit-learn]
draft: false
---

The following example is inspired by the scikit-learn documentation displaying a calibration curve.

## Load data and fit models

```{python}
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.calibration import CalibratedClassifierCV
import numpy as np
from sklearn.svm import LinearSVC

X, y = make_classification(
    n_samples=10_000, n_features=20, n_informative=2, n_redundant=10, random_state=42
)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.99, random_state=42
)

lr = LogisticRegression(C=1.0)
gnb = GaussianNB()
gnb_isotonic = CalibratedClassifierCV(gnb, cv=2, method="isotonic")
gnb_sigmoid = CalibratedClassifierCV(gnb, cv=2, method="sigmoid")

lr.fit(X_train, y_train)
gnb.fit(X_train, y_train)
gnb_isotonic.fit(X_train, y_train)
gnb_sigmoid.fit(X_train, y_train)

y_proba_lr = lr.predict_proba(X_test)[:, 1]
y_proba_gnb = gnb.predict_proba(X_test)[:, 1]
y_proba_gnb_isotonic = gnb_isotonic.predict_proba(X_test)[:, 1]
y_proba_gnb_sigmoid = gnb_sigmoid.predict_proba(X_test)[:, 1]

class NaivelyCalibratedLinearSVC(LinearSVC):
    """LinearSVC with `predict_proba` method that naively scales
    `decision_function` output for binary classification."""

    def fit(self, X, y):
        super().fit(X, y)
        df = self.decision_function(X)
        self.df_min_ = df.min()
        self.df_max_ = df.max()

    def predict_proba(self, X):
        """Min-max scale output of `decision_function` to [0, 1]."""
        df = self.decision_function(X)
        calibrated_df = (df - self.df_min_) / (self.df_max_ - self.df_min_)
        proba_pos_class = np.clip(calibrated_df, 0, 1)
        proba_neg_class = 1 - proba_pos_class
        proba = np.c_[proba_neg_class, proba_pos_class]
        return proba

svc = NaivelyCalibratedLinearSVC(max_iter=10_000)
svc_isotonic = CalibratedClassifierCV(svc, cv=2, method="isotonic")
svc_sigmoid = CalibratedClassifierCV(svc, cv=2, method="sigmoid")

svc.fit(X_train, y_train)
svc_isotonic.fit(X_train, y_train)
svc_sigmoid.fit(X_train, y_train)

y_proba_svc = svc.predict_proba(X_test)[:, 1]
y_proba_svc_isotonic = svc_isotonic.predict_proba(X_test)[:, 1]
y_proba_svc_sigmoid = svc_sigmoid.predict_proba(X_test)[:, 1]
```

## `rtichoke` Workaround

The current version of `rtichoke` has a bug where the calibration plot does not respect the order of the deciles. This is because the data is sorted by decile number instead of the mean predicted probability. The following code provides a workaround for this issue by manually calculating the calibration curve data and plotting it with `plotly`.

```{python}
import polars as pl
import plotly.graph_objects as go
from plotly.subplots import make_subplots

def _make_deciles_dat_binary(
    probs: dict[str, np.ndarray],
    reals: np.ndarray,
    n_bins: int = 10,
) -> pl.DataFrame:
    y = np.asarray(reals).ravel()
    n = y.shape[0]
    frames = []
    for model, p in probs.items():
        p = np.asarray(p).ravel()
        if p.shape[0] != n:
            raise ValueError(
                f"probs['{model}'] length={p.shape[0]} does not match reals length={n}."
            )
        frames.append(
            pl.DataFrame(
                {
                    "reference_group": model,
                    "model": model,
                    "prob": p.astype(float, copy=False),
                    "real": y.astype(float, copy=False),
                }
            )
        )

    df = pl.concat(frames, how="vertical")

    labels = [str(i) for i in range(1, n_bins + 1)]

    df = df.with_columns(
        [
            pl.col("prob").cast(pl.Float64),
            pl.col("real").cast(pl.Float64),
            pl.col("prob")
            .qcut(n_bins, labels=labels, allow_duplicates=True)
            .over(["reference_group", "model"])
            .alias("decile"),
        ]
    ).with_columns(pl.col("decile").cast(pl.Int32))

    deciles_data = (
        df.group_by(["reference_group", "model", "decile"])
        .agg(
            [
                pl.len().alias("n"),
                pl.mean("prob").alias("x"),
                pl.mean("real").alias("y"),
                pl.sum("real").alias("n_reals"),
            ]
        )
        .sort(["reference_group", "model", "x"])  # Sort by mean predicted probability
    )

    return deciles_data


def create_calibration_curve_workaround(
    probs: dict[str, np.ndarray],
    reals: np.ndarray,
    n_bins: int = 10,
    size: int = 600,
    color_values: list[str] = [
        "#1b9e77",
        "#d95f02",
        "#7570b3",
        "#e7298a",
        "#07004D",
        "#E6AB02",
        "#FE5F55",
        "#54494B",
        "#006E90",
        "#BC96E6",
        "#52050A",
        "#1F271B",
        "#BE7C4D",
        "#63768D",
        "#08A045",
        "#320A28",
        "#82FF9E",
        "#2176FF",
        "#D1603D",
        "#585123",
    ],
) -> go.Figure:
    deciles_data = _make_deciles_dat_binary(probs, reals, n_bins)

    fig = make_subplots(
        rows=2, cols=1, shared_xaxes=True, x_title="Predicted", row_heights=[0.8, 0.2]
    )

    fig.update_layout(
        {
            "xaxis": {"showgrid": False},
            "yaxis": {"showgrid": False},
            "barmode": "overlay",
            "plot_bgcolor": "rgba(0, 0, 0, 0)",
            "legend": {
                "orientation": "h",
                "xanchor": "center",
                "yanchor": "top",
                "x": 0.5,
                "y": 1.3,
                "bgcolor": "rgba(0, 0, 0, 0)",
            },
            "showlegend": True,
        }
    )

    x_ref = np.linspace(0, 1, 101)
    reference_data = pl.DataFrame({"x": x_ref, "y": x_ref})

    fig.add_trace(
        go.Scatter(
            x=reference_data["x"],
            y=reference_data["y"],
            name="Perfectly Calibrated",
            legendgroup="Perfectly Calibrated",
            hoverinfo="text",
            line={
                "width": 2,
                "dash": "dot",
                "color": "#BEBEBE",
            },
            showlegend=False,
        ),
        row=1,
        col=1,
    )

    reference_groups = deciles_data["reference_group"].unique().to_list()

    for i, reference_group in enumerate(reference_groups):
        dec_sub = deciles_data.filter(
            pl.col("reference_group") == reference_group
        )

        fig.add_trace(
            go.Scatter(
                x=dec_sub.get_column("x").to_list(),
                y=dec_sub.get_column("y").to_list(),
                name=reference_group,
                legendgroup=reference_group,
                hoverinfo="text",
                mode="lines+markers",
                marker={
                    "size": 10,
                    "color": color_values[i % len(color_values)],
                },
            ),
            row=1,
            col=1,
        )

    fig.update_layout(
        width=size,
        height=size,
    )

    return fig
```

## Gaussian Naive Bayes

::: {.panel-tabset}

### rtichoke (workaround)

```{python}
import plotly.io as pio
pio.renderers.default = "plotly_mimetype+notebook_connected"

create_calibration_curve_workaround(
    probs={
        "Logistic": y_proba_lr,
        "Naive Bayes": y_proba_gnb,
        "Naive Bayes + Isotonic": y_proba_gnb_isotonic,
        "Naive Bayes + Sigmoid": y_proba_gnb_sigmoid,
    },
    reals=y_test
)
```

### scikit-learn

```{python}
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
from sklearn.calibration import CalibrationDisplay

clf_list = [
    (lr, "Logistic"),
    (gnb, "Naive Bayes"),
    (gnb_isotonic, "Naive Bayes + Isotonic"),
    (gnb_sigmoid, "Naive Bayes + Sigmoid"),
]

fig = plt.figure(figsize=(10, 10))
gs = GridSpec(4, 2)
colors = plt.get_cmap("Dark2")

ax_calibration_curve = fig.add_subplot(gs[:2, :2])
calibration_displays = {}
for i, (clf, name) in enumerate(clf_list):
    display = CalibrationDisplay.from_estimator(
        clf,
        X_test,
        y_test,
        n_bins=10,
        name=name,
        ax=ax_calibration_curve,
        color=colors(i),
    )
    calibration_displays[name] = display

ax_calibration_curve.grid()
ax_calibration_curve.set_title("Calibration plots (Naive Bayes)")

# Add histogram
grid_positions = [(2, 0), (2, 1), (3, 0), (3, 1)]
for i, (_, name) in enumerate(clf_list):
    row, col = grid_positions[i]
    ax = fig.add_subplot(gs[row, col])

    ax.hist(
        calibration_displays[name].y_prob,
        range=(0, 1),
        bins=10,
        label=name,
        color=colors(i),
    )
    ax.set(title=name, xlabel="Mean predicted probability", ylabel="Count")

plt.tight_layout()
plt.show()
```

:::

## Linear SVC

::: {.panel-tabset}

### rtichoke (workaround)

```{python}
create_calibration_curve_workaround(
    probs={
        "Logistic": y_proba_lr,
        "SVC": y_proba_svc,
        "SVC + Isotonic": y_proba_svc_isotonic,
        "SVC + Sigmoid": y_proba_svc_sigmoid,
    },
    reals=y_test
)
```

### scikit-learn

```{python}
clf_list = [
    (lr, "Logistic"),
    (svc, "SVC"),
    (svc_isotonic, "SVC + Isotonic"),
    (svc_sigmoid, "SVC + Sigmoid"),
]

fig = plt.figure(figsize=(10, 10))
gs = GridSpec(4, 2)

ax_calibration_curve = fig.add_subplot(gs[:2, :2])
calibration_displays = {}
for i, (clf, name) in enumerate(clf_list):
    display = CalibrationDisplay.from_estimator(
        clf,
        X_test,
        y_test,
        n_bins=10,
        name=name,
        ax=ax_calibration_curve,
        color=colors(i),
    )
    calibration_displays[name] = display

ax_calibration_curve.grid()
ax_calibration_curve.set_title("Calibration plots (SVC)")

# Add histogram
grid_positions = [(2, 0), (2, 1), (3, 0), (3, 1)]
for i, (_, name) in enumerate(clf_list):
    row, col = grid_positions[i]
    ax = fig.add_subplot(gs[row, col])

    ax.hist(
        calibration_displays[name].y_prob,
        range=(0, 1),
        bins=10,
        label=name,
        color=colors(i),
    )
    ax.set(title=name, xlabel="Mean predicted probability", ylabel="Count")

plt.tight_layout()
plt.show()
```

:::
